---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About Me
I am a Principal Applied Scientist at Amazon AGI, leading the development of large multimodal understanding models under the Nova family. My work spans the design and implementation of multimodal encoders, the establishment of training pipelines for pre-training, fine-tuning, and reinforcement learning (PT/SFT/PPO) for multimodal content (image, video, audio and text), as well as model evaluation and deployment. Nova models achieve state-of-the-art video understanding performance and are now serving customers in media, entertainment, and security domains. I also lead research on next-generation architectures for unified understanding and generation.

Before joining AGI, I was a Staff Research Scientist at ByteDance, focusing on large multimodal modeling, and previously a Senior Applied Scientist at AWS AI, where I led video and multimodal understanding research powering services such as Rekognition Video, ad insertion, and Prime Video content intelligence.

I received my Ph.D. Degree (2018) at [Rutgers University](https://www.rutgers.edu/) supervised by Prof. Ivan Marsic and my Bachelorâ€™s Degree (2013) at [University of Electronic Science and Technology of China](https://www.uestc.edu.cn/).


# News
* [**2025**] **ICCV 2025** Publication. [Paper](https://iccv.thecvf.com/virtual/2025/poster/2604)
* [**2025**] **Nova Models** Nova Premier. [Tech report](https://assets.amazon.science/e5/e6/ccc5378c42dca467d1abe1628ec9/amazon-nova-premier-technical-report-and-model-card.pdf)
* [**2025**] **WACV 2025** publications: "GEXIA: Granularity Expansion and Iterative Approximation for Scalable Multi-grained Video-language Learning". [Paper](https://assets.amazon.science/f0/a3/89edae924f98888b693812fa1bcc/gexia-granularity-expansion-and-iterative-approximation-for-scalable-multi-grained-video-language-learning.pdf)
* [**2025**] **WACV 2025** publications: "Now You See Me: Context-Aware Automatic Audio Description". [Paper](https://assets.amazon.science/a3/c2/ce0b893b42518f664fc0018a34b2/now-you-see-me-context-aware-automatic-audio-description.pdf)
* [**2024**] **Nova Models** Amazon Nova model family. [Tech report](https://assets.amazon.science/9f/a3/ae41627f4ab2bde091f1ebc6b830/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf)
* [**2024**] **NeurIPS 2024** publication: "Video token merging for long-form video understanding". [Paper](https://arxiv.org/pdf/2410.23782)
* [**2024**] **ECCV 2024** publication: "Text-Guided Video Masked Autoencoder". [Paper](https://arxiv.org/abs/2408.0075)
* [**2023**] **ICCV 2023** publication: "Motion-Guided Masking for Spatiotemporal Representation Learning". [Paper](https://arxiv.org/pdf/2303.14865.pdf)
* [**2023**] **ICCV 2023** publication: "MEGA: Multimodal Alignment Aggregation and Distillation For Cinematic Video Segmentation". [Paper](https://arxiv.org/pdf/2303.14865.pdf)
* [**2023**] **CVPR 2023** publication: "Revisiting multimodal representation in contrastive learning: from patch and token embeddings to finite discrete tokens". [Paper](https://arxiv.org/pdf/2303.14865.pdf)
* [**2023**] **ICASSP 2023** publication: "CAT: Causal Audio Transformer for Audio Classification". [Paper](https://arxiv.org/abs/2303.07626)
* [**2023**] **ICLR 2023** publication: "Nearest-Neighbor Inter-Intra Contrastive Learning from Unlabeled Videos". [Paper](https://arxiv.org/pdf/2303.07317.pdf)
* [**2023**] **WACV 2023** publication: "Discrete Cosin TransFormer: Image Modeling From Frequency Domain". [Paper](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Discrete_Cosin_TransFormer_Image_Modeling_From_Frequency_Domain_WACV_2023_paper.pdf)
* [**2022**] **CVPR 2022 (Oral)** publication: "TubeR: Tubelet Transformer for Video Action Detection". [Paper](https://arxiv.org/abs/2104.00969)
* [**2022**] **CVPR 2022** publication: "Id-Free Person Similarity Learning". [Paper](https://www.amazon.science/publications/id-free-person-similarity-learning)
* [**2022**] **CVPR 2022 (Oral)** publication: "What to Look at and Where: Semantic and Spatial Refined Transformer for Detecting Human-Object Interactions". [Paper](https://arxiv.org/abs/2204.00746)
* [**2022**] **CVPR 2022 (Oral)** publication: "Temporal Gradient Dropout: A Memory Efficient Strategy for Training Video Models". [Paper](https://arxiv.org/pdf/2203.16755.pdf)
* [**2022**] **WACV 2022** Two papers accepted by WACV 2022: [NUTA](https://arxiv.org/pdf/2012.08041.pdf) and [SSCAP](https://arxiv.org/pdf/2105.14158.pdf).
* [**2021**] **NeurIPS 2021 (Spotlight)** "Long Short-Term Transformer for Online Action Detection". [Paper](https://arxiv.org/abs/2107.03377)
* [**2021**] GluonMM is now available [Link](https://github.com/amazon-research/gluonmm)
* [**2021**] **ICCV 2021** publication: "VidTr: Video Transformer Without Convolutions". [Paper](https://arxiv.org/abs/2104.11746)
* [**2021**] **ICCV 2021** publication: "Selective Feature Compression for Efficient Activity Recognition Inference". [Paper](https://arxiv.org/pdf/2104.00179.pdf)
* [**2021**] **CVPR 2021** publication: "Multi-Label Activity Recognition using Activity-specific Features and Activity Correlations". [Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Multi-Label_Activity_Recognition_Using_Activity-Specific_Features_and_Activity_Correlations_CVPR_2021_paper.pdf)
* [**2021**] **CVPR 2021** publication: "SiamMOT: Siamese Multi-Object Tracking". [Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Shuai_SiamMOT_Siamese_Multi-Object_Tracking_CVPR_2021_paper.pdf)
